Je crée de nouveaux algorithmes d'apprentissage statistique pour
résoudre des problèmes d'analyse de données dans des domaines
scientifiques tels que la médecine la biologie. Mes recherches
précédantes étaient axées sur des nouveaux modèles d'apprentissage
pour le regroupement (clustering), la régression, la détection des
ruptures, le classement (ranking) et la classification. Mes
contributions à la littérature de la statistique et l'apprentissage
automatique sont des algorithmes pour résoudre efficacement ces
problèmes d'optimisation. Je suis particulièrement intéressé à
développer des algorithmes suffisamment rapides pour l'étiquetage
interactif et l'apprentissage automatique supervisé dans les grands
ensembles de données. Ce qui suit est un résumé de mes recherches
antérieures, et mon plan de recherche pour l'avenir.

\section{Algorithmes de détection de rupture avec applications aux données de nombre de copies d'ADN}

Pendant mon doctorat à Paris, j'ai travaillé en collaboration avec des
médecins de l'Institut Curie sur les méthodes d'apprentissage
automatique pour le diagnostic de neuroblastome, un cancer qui est
fréquent chez les enfants. Les médecins voulaient donner des
traitements ciblés basés sur le nombre de ruptures dans les données de
nombre de copies de l'ADN de la tumeur du patient. En utilisant des
algorithmes existants pour la détection des ruptures, les médecins ont
constaté des taux d'erreur trop grand (par rapport à leur
interprétation visuelle du signal et bruit dans ces données). Ma
contribution était de développer des nouveaux algorithmes basés sur
des étiquettes fournies par les médecins.

\paragraph{Nouvelle méthode d'étiquetage pour la détection supervisée des ruptures.}

Dans notre papier de \emph{BMC Bioinformatics}
\citep{HOCKING-breakpoints}, nous avons proposé une nouvelle
formulation supervisée pour le problème de détection de ruptures. Dans
notre formulation, les médecins ont d'abord étiqueté un sous-ensemble
de leurs données avec des régions positives qui contiennent des
ruptures, et des régions négatives qui ne contiennent pas de rupture.
Nous avons proposé une méthode pour l'entrainement des algorithmes
existants, en choissisant des paramètres qui minimisent le nombre de
étiquettes incorrectes. Nous avons comparé les algorithmes en
calculant le nombre de étiquettes classées correctement dans un
ensemble de test. Nous avons démontré que la meilleure méthode
existante était un modèle de détection de rupture qui maximise la
vraisemblance gaussienne.  Dans cet article, nous avons sélectionné le
nombre de changements en utilisant un fonction de pénalité univariée
qui dépend uniquement du nombre de données, et dans notre prochain
article, nous avons étudié une généralisation pour les fonctions de
pénalité multivariées.

\paragraph{Modèles de régression pour apprendre la fonction de pénalité.}

Dans un travail publié à \emph{ICML'13} \citep{HOCKING-penalties},
nous avons proposé un algorithme pour apprendre la fonction de
pénalité dans les modèles de détection de ruptures. Nous avons
démontré que l'apprentissage d'une fonction de pénalité pour
sélectionner le nombre de ruptures est un problème de régression avec
sorties censurées. Nous avons proposé d'apprendre une fonction de
pénalité linéaire, en minimisant une fonction de perte convexe qui
exploite la structure des sorties censurées. Notre contribution
principale était une nouvelle algorithme efficace pour résoudre ce
problème d'optimisation convexe. Nous avons démontré que notre
algorithme apprend une fonction de pénalité multivariée, et fournit
des taux d'erreur moins élevé que la pénalité univariée
précédente. J'ai implémenté ces algorithmes dans le paquetage
penaltyLearning dans R, que j'ai présenté lors d'un tutoriel à
\emph{useR2017} \citep{change-tutoriel}. Dans des travaux plus récents
qui ont été acceptés pour publication à \emph{NIPS'17} \citep{MMIT},
nous avons proposé un algorithme pour apprendre une fonction de
penalité non-linéaire grâce à un arbre de décision.
